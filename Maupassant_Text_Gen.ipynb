{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Maupassant_Text_Gen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQRbWqj9w-EK"
      },
      "source": [
        "# Génération de text à la façon de Guy de Maupassant.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=\"700\" height=\"400\" src=\"https://github.com/AxelDucamp/PROJET_Text_Generation_Maupassant/blob/main/guy-de-maupassant.jpg?raw=true\">\n",
        "</p>\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# Le projet :\n",
        "\n",
        "Ce projet rapide a pour objectif de générer du texte à la façon de Guy de Maupassant. Pour se faire, j'ai utilisé le livre Bel Ami comme base de données. \n",
        "Parfois le texte généré est..plutôt surprenant! (mais amusant)\n",
        "\n",
        "Le notebook a été exécuté sur Google Colab (25 Go de Ram et GPU Tesla P100). L'\n",
        "entraînement du modèle s'est effectué en environ 1h.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I28XCXYVX_7s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
        "import numpy as np\n",
        "import re\n",
        "import io\n",
        "from os import path"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwiNQ6VIZbB2",
        "outputId": "bdc17086-2a27-4cfb-b6d0-857e0de64173"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiMgAsEqygAk"
      },
      "source": [
        "# Importation et preprocessing :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcxGO8AvZeCJ"
      },
      "source": [
        "file = open('/content/drive/MyDrive/Colab Notebooks/Projets/NLP_Text_Génération/Maupassant.txt','r', encoding='UTF-8')#_complet\n",
        "content = file.readlines()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYbcTR0WZ0cs",
        "outputId": "6a1036cd-1150-48b1-8e8d-7247c55dd8aa"
      },
      "source": [
        "content[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Quand la caissière lui eut rendu la monnaie de sa pièce de cent sous, Georges Duroy sortit du restaurant.\\n',\n",
              " 'Comme il portait beau par nature et par pose d’ancien sous-officier, il cambra sa taille, frisa sa moustache d’un geste militaire et familier, et jeta sur les dîneurs attardés un regard rapide et circulaire, un de ces regards de joli garçon, qui s’étendent comme des coups d’épervier.\\n',\n",
              " 'Les femmes avaient levé la tête vers lui, trois petites ouvrières, une maîtresse de musique entre deux âges, mal peignée, négligée, coiffée d’un chapeau toujours poussiéreux et vêtue toujours d’une robe de travers, et deux bourgeoises avec leurs maris, habituées de cette gargote à prix fixe.\\n',\n",
              " 'Lorsqu’il fut sur le trottoir, il demeura un instant immobile, se demandant ce qu’il allait faire. On était au 28 juin, et il lui restait juste en poche trois francs quarante pour finir le mois. Cela représentait deux dîners sans déjeuners, ou deux déjeuners sans dîners, au choix. Il réfléchit que les repas du matin étant de vingt-deux sous, au lieu de trente que coûtaient ceux du soir, il lui resterait, en se contentant des déjeuners, un franc vingt centimes de boni, ce qui représentait encore deux collations au pain et au saucisson, plus deux bocks sur le boulevard. C’était là sa grande dépense et son grand plaisir des nuits ; et il se mit à descendre la rue Notre-Dame-de-Lorette.\\n',\n",
              " 'Il marchait ainsi qu’au temps où il portait l’uniforme des hussards, la poitrine bombée, les jambes un peu entrouvertes comme s’il venait de descendre de cheval ; et il avançait brutalement dans la rue pleine de monde, heurtant les épaules, poussant les gens pour ne point se déranger de sa route. Il inclinait légèrement sur l’oreille son chapeau à haute forme assez défraîchi, et battait le pavé de son talon. Il avait l’air de toujours défier quelqu’un, les passants, les maisons, la ville entière, par chic de beau soldat tombé dans le civil.\\n',\n",
              " 'Quoique habillé d’un complet de soixante francs, il gardait une certaine élégance tapageuse, un peu commune, réelle cependant. Grand, bien fait, blond, d’un blond châtain vaguement roussi, avec une moustache retroussée, qui semblait mousser sur sa lèvre, des yeux bleus, clairs, troués d’une pupille toute petite, des cheveux frisés naturellement, séparés par une raie au milieu du crâne, il ressemblait bien au mauvais sujet des romans populaires.\\n',\n",
              " 'C’était une de ces soirées d’été où l’air manque dans Paris. La ville, chaude comme une étuve, paraissait suer dans la nuit étouffante. Les égouts soufflaient par leurs bouches de granit leurs haleines empestées ; et les cuisines souterraines jetaient à la rue, par leurs fenêtres basses, les miasmes infâmes des eaux de vaisselle et des vieilles sauces.\\n',\n",
              " 'Les concierges, en manches de chemise, à cheval sur des chaises en paille, fumaient la pipe sous des portes cochères, et les passants allaient d’un pas accablé, le front nu, le chapeau à la main.\\n',\n",
              " 'Quand Georges Duroy parvint au boulevard, il s’arrêta encore, indécis sur ce qu’il allait faire. Il avait envie maintenant de gagner les Champs-Élysées et l’avenue du Bois de Boulogne pour trouver un peu d’air frais, sous les arbres ; mais un désir aussi le travaillait, celui d’une rencontre amoureuse.\\n',\n",
              " 'Comment se présenterait-elle ? Il n’en savait rien, mais il l’attendait depuis trois mois, tous les jours, tous les soirs. Quelquefois cependant, grâce à sa belle mine et à sa tournure galante, il volait, par-ci par-là, un peu d’amour, mais il espérait toujours plus et mieux.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2UxxK_Z6Z4"
      },
      "source": [
        "script = [part_text.strip() for part_text in content]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TB6x9PrakrV"
      },
      "source": [
        "def step_preprocessing(corpus):\n",
        "  df_step2 = list()\n",
        "  for sentences in script:\n",
        "    sentence = re.findall(r'[A-Za-z0-9êçù.éàè?!]+',sentences)\n",
        "    liste_temp = []\n",
        "    for word in sentence:\n",
        "      word = word.lower()\n",
        "      ponctuation = re.findall(r'[?!.]',word)\n",
        "      mot_sans_ponctuation = re.findall(r'[^?!.]+',word)\n",
        "      try:\n",
        "        liste_temp.append(mot_sans_ponctuation[0])\n",
        "      except:\n",
        "        ...\n",
        "      try:\n",
        "        liste_temp.append(ponctuation[0])\n",
        "      except:\n",
        "        continue\n",
        "    df_step2.append(liste_temp)\n",
        "    df_step3 = list()\n",
        "    for i in range(len(df_step2)):\n",
        "      df_step3.append(' '.join(df_step2[i]))\n",
        "  return df_step3\n",
        "df_step3 = step_preprocessing(script)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EViWKZvaF1vb",
        "outputId": "6ea4b75e-7409-4087-9b7d-c342a8c82d30"
      },
      "source": [
        "df_step3[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['quand la caissière lui eut rendu la monnaie de sa pièce de cent sous georges duroy sortit du restaurant .',\n",
              " 'comme il portait beau par nature et par pose d ancien sous officier il cambra sa taille frisa sa moustache d un geste militaire et familier et jeta sur les d neurs attardés un regard rapide et circulaire un de ces regards de joli garçon qui s étendent comme des coups d épervier .',\n",
              " 'les femmes avaient levé la tête vers lui trois petites ouvrières une ma tresse de musique entre deux ges mal peignée négligée coiffée d un chapeau toujours poussiéreux et vêtue toujours d une robe de travers et deux bourgeoises avec leurs maris habituées de cette gargote à prix fixe .',\n",
              " 'lorsqu il fut sur le trottoir il demeura un instant immobile se demandant ce qu il allait faire . on était au 28 juin et il lui restait juste en poche trois francs quarante pour finir le mois . cela représentait deux d ners sans déjeuners ou deux déjeuners sans d ners au choix . il réfléchit que les repas du matin étant de vingt deux sous au lieu de trente que co taient ceux du soir il lui resterait en se contentant des déjeuners un franc vingt centimes de boni ce qui représentait encore deux collations au pain et au saucisson plus deux bocks sur le boulevard . c était là sa grande dépense et son grand plaisir des nuits et il se mit à descendre la rue notre dame de lorette .',\n",
              " 'il marchait ainsi qu au temps où il portait l uniforme des hussards la poitrine bombée les jambes un peu entrouvertes comme s il venait de descendre de cheval et il avançait brutalement dans la rue pleine de monde heurtant les épaules poussant les gens pour ne point se déranger de sa route . il inclinait légèrement sur l oreille son chapeau à haute forme assez défra chi et battait le pavé de son talon . il avait l air de toujours défier quelqu un les passants les maisons la ville entière par chic de beau soldat tombé dans le civil .',\n",
              " 'quoique habillé d un complet de soixante francs il gardait une certaine élégance tapageuse un peu commune réelle cependant . grand bien fait blond d un blond ch tain vaguement roussi avec une moustache retroussée qui semblait mousser sur sa lèvre des yeux bleus clairs troués d une pupille toute petite des cheveux frisés naturellement séparés par une raie au milieu du cr ne il ressemblait bien au mauvais sujet des romans populaires .',\n",
              " 'c était une de ces soirées d été où l air manque dans paris . la ville chaude comme une étuve paraissait suer dans la nuit étouffante . les égouts soufflaient par leurs bouches de granit leurs haleines empestées et les cuisines souterraines jetaient à la rue par leurs fenêtres basses les miasmes inf mes des eaux de vaisselle et des vieilles sauces .',\n",
              " 'les concierges en manches de chemise à cheval sur des chaises en paille fumaient la pipe sous des portes cochères et les passants allaient d un pas accablé le front nu le chapeau à la main .',\n",
              " 'quand georges duroy parvint au boulevard il s arrêta encore indécis sur ce qu il allait faire . il avait envie maintenant de gagner les champs lysées et l avenue du bois de boulogne pour trouver un peu d air frais sous les arbres mais un désir aussi le travaillait celui d une rencontre amoureuse .',\n",
              " 'comment se présenterait elle ? il n en savait rien mais il l attendait depuis trois mois tous les jours tous les soirs . quelquefois cependant gr ce à sa belle mine et à sa tournure galante il volait par ci par là un peu d amour mais il espérait toujours plus et mieux .']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N63cbeaga_h9",
        "outputId": "66171440-8f8b-4e30-e8ce-c8affb4493ca"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(df_step3)\n",
        "inp_sequences[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[75, 4],\n",
              " [75, 4, 5423],\n",
              " [75, 4, 5423, 24],\n",
              " [75, 4, 5423, 24, 201],\n",
              " [75, 4, 5423, 24, 201, 2261],\n",
              " [75, 4, 5423, 24, 201, 2261, 4],\n",
              " [75, 4, 5423, 24, 201, 2261, 4, 1167],\n",
              " [75, 4, 5423, 24, 201, 2261, 4, 1167, 1],\n",
              " [75, 4, 5423, 24, 201, 2261, 4, 1167, 1, 35],\n",
              " [75, 4, 5423, 24, 201, 2261, 4, 1167, 1, 35, 475]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiTur1_8bgfG"
      },
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = 30\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOe2ADjCym-N"
      },
      "source": [
        "# Construction du modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv16WUnPbu6w",
        "outputId": "b2790a5b-5f7c-4442-faf6-00034a5fa7da"
      },
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 300, input_length=input_len))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 29, 300)           3174300   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10581)             1068681   \n",
            "=================================================================\n",
            "Total params: 4,403,381\n",
            "Trainable params: 4,403,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqa3pHu4RdO8"
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEUlXmv1bwqg",
        "outputId": "cf3216c4-d17b-4c54-a974-0e6f6f4b742c"
      },
      "source": [
        "model.fit(predictors, label, epochs=200,callbacks=earlystop)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3394/3394 [==============================] - 26s 7ms/step - loss: 6.6355\n",
            "Epoch 2/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 5.7619\n",
            "Epoch 3/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 5.2254\n",
            "Epoch 4/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 4.8041\n",
            "Epoch 5/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 4.4370\n",
            "Epoch 6/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 4.1104\n",
            "Epoch 7/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 3.8069\n",
            "Epoch 8/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 3.5313\n",
            "Epoch 9/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 3.2793\n",
            "Epoch 10/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 3.0521\n",
            "Epoch 11/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.8522\n",
            "Epoch 12/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.6664\n",
            "Epoch 13/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.4995\n",
            "Epoch 14/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.3540\n",
            "Epoch 15/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.2197\n",
            "Epoch 16/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 2.1003\n",
            "Epoch 17/200\n",
            "3394/3394 [==============================] - 27s 8ms/step - loss: 1.9903\n",
            "Epoch 18/200\n",
            "3394/3394 [==============================] - 27s 8ms/step - loss: 1.8984\n",
            "Epoch 19/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.8077\n",
            "Epoch 20/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.7330\n",
            "Epoch 21/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.6589\n",
            "Epoch 22/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.5975\n",
            "Epoch 23/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.5334\n",
            "Epoch 24/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.4816\n",
            "Epoch 25/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.4370\n",
            "Epoch 26/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.3936\n",
            "Epoch 27/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.3470\n",
            "Epoch 28/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.3159\n",
            "Epoch 29/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.2799\n",
            "Epoch 30/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.2457\n",
            "Epoch 31/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.2128\n",
            "Epoch 32/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.1896\n",
            "Epoch 33/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.1727\n",
            "Epoch 34/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.1425\n",
            "Epoch 35/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.1269\n",
            "Epoch 36/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.1072\n",
            "Epoch 37/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0817\n",
            "Epoch 38/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0654\n",
            "Epoch 39/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0491\n",
            "Epoch 40/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0360\n",
            "Epoch 41/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0219\n",
            "Epoch 42/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 1.0122\n",
            "Epoch 43/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9967\n",
            "Epoch 44/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9834\n",
            "Epoch 45/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9743\n",
            "Epoch 46/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9658\n",
            "Epoch 47/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9592\n",
            "Epoch 48/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9418\n",
            "Epoch 49/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9345\n",
            "Epoch 50/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9313\n",
            "Epoch 51/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9270\n",
            "Epoch 52/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9181\n",
            "Epoch 53/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9054\n",
            "Epoch 54/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.9039\n",
            "Epoch 55/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8963\n",
            "Epoch 56/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8938\n",
            "Epoch 57/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8874\n",
            "Epoch 58/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8812\n",
            "Epoch 59/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8751\n",
            "Epoch 60/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8749\n",
            "Epoch 61/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8658\n",
            "Epoch 62/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8614\n",
            "Epoch 63/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8563\n",
            "Epoch 64/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8484\n",
            "Epoch 65/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8464\n",
            "Epoch 66/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8489\n",
            "Epoch 67/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8457\n",
            "Epoch 68/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8494\n",
            "Epoch 69/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8421\n",
            "Epoch 70/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8362\n",
            "Epoch 71/200\n",
            "3394/3394 [==============================] - 24s 7ms/step - loss: 0.8375\n",
            "Epoch 72/200\n",
            "3394/3394 [==============================] - 25s 7ms/step - loss: 0.8356\n",
            "Epoch 73/200\n",
            "3394/3394 [==============================] - 25s 7ms/step - loss: 0.8303\n",
            "Epoch 74/200\n",
            "3394/3394 [==============================] - 25s 7ms/step - loss: 0.8290\n",
            "Epoch 75/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8289\n",
            "Epoch 76/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8221\n",
            "Epoch 77/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8290\n",
            "Epoch 78/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8232\n",
            "Epoch 79/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8227\n",
            "Epoch 80/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8232\n",
            "Epoch 81/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8232\n",
            "Epoch 82/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8232\n",
            "Epoch 83/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8193\n",
            "Epoch 84/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8151\n",
            "Epoch 85/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8137\n",
            "Epoch 86/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8108\n",
            "Epoch 87/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8107\n",
            "Epoch 88/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8216\n",
            "Epoch 89/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8155\n",
            "Epoch 90/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8104\n",
            "Epoch 91/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8135\n",
            "Epoch 92/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8043\n",
            "Epoch 93/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8079\n",
            "Epoch 94/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8068\n",
            "Epoch 95/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8105\n",
            "Epoch 96/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8070\n",
            "Epoch 97/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8106\n",
            "Epoch 98/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8088\n",
            "Epoch 99/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8075\n",
            "Epoch 100/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8151\n",
            "Epoch 101/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8081\n",
            "Epoch 102/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8065\n",
            "Epoch 103/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8069\n",
            "Epoch 104/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8146\n",
            "Epoch 105/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8073\n",
            "Epoch 106/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8095\n",
            "Epoch 107/200\n",
            "3394/3394 [==============================] - 26s 8ms/step - loss: 0.8119\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1696517750>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJXKUxN6bYfZ"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Projets/NLP_Text_Génération/model_embed_300_final')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5by8Yhdnnvp"
      },
      "source": [
        "# Embedding Projector\n",
        "\n",
        "Utilisation du site [Embedding Projector](https://projector.tensorflow.org/) de Tensorflow afin de visualiser le word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGM344rphOfR"
      },
      "source": [
        "weights = model.layers[0].get_weights()[0]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIqMMRlpncEv"
      },
      "source": [
        "out_v = io.open(path.join('/content', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('/content', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in tokenizer.word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MIoBW9a_9KI"
      },
      "source": [
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=\"500\" height=\"400\" src=\"https://github.com/AxelDucamp/PROJET_Text_Generation_Maupassant/blob/main/Embedding_Projector.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy-R3cGjqxwq"
      },
      "source": [
        "# Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84T7v9Fkg_Y1"
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len,iter):\n",
        "    output_temp = \"\"\n",
        "    for iteration in range(iter):\n",
        "      if iteration == 0:\n",
        "        for _ in range(next_words):\n",
        "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "            predicted = np.argmax(model.predict(token_list, verbose=0))\n",
        "            \n",
        "            output_word = \"\"\n",
        "            for word,index in tokenizer.word_index.items():\n",
        "                if index == predicted:\n",
        "                    output_word = word\n",
        "                    break\n",
        "            seed_text += \" \"+output_word\n",
        "            output_temp = seed_text.title()\n",
        "      else:\n",
        "        for _ in range(next_words):\n",
        "          text_suite = \" \".join(output_temp.split()[-3:])\n",
        "          token_list = tokenizer.texts_to_sequences([text_suite])[0]\n",
        "          token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "          predicted = np.argmax(model.predict(token_list, verbose=0))\n",
        "          \n",
        "          output_word = \"\"\n",
        "          for word,index in tokenizer.word_index.items():\n",
        "              if index == predicted:\n",
        "                  output_word = word\n",
        "                  break\n",
        "          output_temp += \" \"+output_word\n",
        "    return output_temp.title()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E99v24mA6LGF",
        "outputId": "760c665a-21f4-4af9-bf72-4d2b15c8e620"
      },
      "source": [
        "print (generate_text(\"Il\", 2, model, max_sequence_len,iter=5))\n",
        "print (generate_text(\"Elle\", 2, model, max_sequence_len,iter=5))\n",
        "\n",
        "print (generate_text(\"La\", 2, model, max_sequence_len,iter=5))\n",
        "print (generate_text(\"Le\", 2, model, max_sequence_len,iter=5))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il Répondit Avec Calme Vous Avez D Abord Chercher Les Visages\n",
            "Elle Se Leva Et Il Alla Vers Le Temps Elle Se\n",
            "La Jeune Femme Répondit Oui Je Veux Bien Bête De Ne\n",
            "Le Père Walter Le Regardait De Tout Seul L Il Revint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBkz9hk0dbT",
        "outputId": "33bbbbbd-0933-4523-e5a5-14c1046614cf"
      },
      "source": [
        "print (generate_text(\"Il allait\", 2, model, max_sequence_len,iter=10))\n",
        "print (generate_text(\"Elle sentait\", 2, model, max_sequence_len,iter=10))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il Allait Les Arracher Tout À Coup Il Eut Peur De La Trinité Murmura Oui Je Vous Aime Comme Ma Petite Fille\n",
            "Elle Sentait Vaguement Qu Il S Approcha D Un Regard Rapide Était Grand Glace Des Salons Où Étaient Là Dans Le Visage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJgVBn-X6t-Y",
        "outputId": "e6391eea-f97f-4b25-a8a9-bef8055b4359"
      },
      "source": [
        "print (generate_text(\"J ai\", 2, model, max_sequence_len,iter=8))\n",
        "print (generate_text(\"Tu es\", 2, model, max_sequence_len,iter=8))\n",
        "print (generate_text(\"Quand\", 2, model, max_sequence_len,iter=8))\n",
        "print (generate_text(\"Quoi\", 2, model, max_sequence_len,iter=8))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J Ai Un Peu Surpris Le Magistrat Demanda Encore Qu Est Ce Que Vous Avez Une Expérience Qui\n",
            "Tu Es Méchante Suzette Ce Monsieur Dit Il Tu Vas Attraper Une Pauvre Femme Déchirée Par Une Inavouable\n",
            "Quand Il Eut Fini Par Le F Reste Depuis Quelques Minutes D Tat Que Tu As Couché\n",
            "Quoi Donc S Étant Assis Sur Un Banc Il S En Voulut De Temps En Temps Elle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE7VmowD8pX1",
        "outputId": "a1da6e02-cf65-48cc-f9ad-200fa13432d4"
      },
      "source": [
        "print (generate_text(\"Pourquoi\", 2, model, max_sequence_len,iter=2))\n",
        "print (generate_text(\"Alors qu il\", 2, model, max_sequence_len,iter=2))\n",
        "print (generate_text(\"Alors qu elle\", 2, model, max_sequence_len,iter=2))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pourquoi Ça N Est Pas\n",
            "Alors Qu Il Ne L Avait Pas\n",
            "Alors Qu Elle S Approcha Un Peu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRFEUdG17YTg",
        "outputId": "c1c5d33b-7bc8-4b6f-c3cd-fdfac5a2e190"
      },
      "source": [
        "print (generate_text(\"Son amie\", 2, model, max_sequence_len,iter=10))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Son Amie Mme Forestier Ne Remuait Point Elle Cria M Laroche Mathieu L Attendait En Montant L Escalier Il Se Releva Toute\n"
          ]
        }
      ]
    }
  ]
}